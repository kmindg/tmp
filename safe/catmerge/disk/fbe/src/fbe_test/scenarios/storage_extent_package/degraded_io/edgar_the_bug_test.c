
/***************************************************************************
 * Copyright (C) EMC Corporation 2011
 * All rights reserved.
 * Licensed material -- property of EMC Corporation
 ***************************************************************************/

/*!**************************************************************************
* @file edgar_the_bug_test.c
***************************************************************************
*
* @brief
*  This test validates that incomplete writes due to an SP going down
*  are flushed by the surviving SP.
*
* @version
*  5/15/2012 - Created from shredder_test.c.  Dave Agans
*
***************************************************************************/

/*************************
*   INCLUDE FILES
*************************/
#include "mut.h"   
#include "fbe/fbe_api_rdgen_interface.h"
#include "fbe/fbe_raid_group.h"
#include "sep_tests.h"
#include "fbe/fbe_winddk.h"
#include "fbe/fbe_service.h"
#include "fbe/fbe_transport.h"
#include "fbe/fbe_api_common.h"
#include "fbe/fbe_api_common_transport.h"
#include "fbe/fbe_api_block_transport_interface.h"
#include "fbe/fbe_api_utils.h"
#include "sep_utils.h"
#include "sep_hook.h"
#include "sep_rebuild_utils.h"        
#include "fbe/fbe_random.h"
#include "fbe/fbe_api_raid_group_interface.h"
#include "fbe/fbe_api_database_interface.h"
#include "fbe_test_common_utils.h"
#include "fbe/fbe_api_scheduler_interface.h"
#include "fbe_testability.h"
#include "fbe/fbe_api_discovery_interface.h"
#include "fbe_test_configurations.h"
#include "pp_utils.h"
#include "fbe_test.h"
#include "fbe/fbe_api_event_log_interface.h"
#include "fbe_raid_error.h"

/*************************
 *   TEST DESCRIPTIONS
 *************************/
char * edgar_the_bug_short_desc = "Test write log flush on SP fail and failover.";
char * edgar_the_bug_long_desc ="\
The edgar_the_bug-test performs SP death during degraded IO and checks that\n\
                       the surviving SP or recovering SP flushes the write log.\n\
\n\
Dependencies:\n\
        - Dual SP \n\
        - Debug Hooks for Write Log Flush.\n\
\n\
STEP 1: Bring SPs up (SPA = Active SP).\n\
STEP 2: Bring up the initial topology.\n\
        - Create and verify the initial physical package config.\n\
STEP 3: Disable background processes and write background pattern to rg.\n\
STEP 4: Insert write log flush start debug hook into raid group condition handler.\n\
STEP 5: Remove drive(s) to create degraded array\n\
STEP 6: Run IO to exercise write log\n\
STEP 7: Shutdown active SP or passive SP\n\
STEP 8: Restart SP (if testing simultaneous restart and flush).\n\
STEP 9: Wait for write log flush start.\n\
STEP 10: If testing passive-active flush, hook peer flush and shutdown target sp;\n\
         - Set flush done hook, clear flush start hook to allow flush to continue.\n\
STEP 11: Wait for flush done.\n\
STEP 12: Check for verify errors on locked out write.\n\
STEP 13: Re-insert drive(s).\n\
STEP 14: Wait for rebuild verify complete and check verify report for no errors.\n\
          - This also verifies that no parity or dead drive errors, flush abandoned errors\n\
            are generated by blocks being written as invalidated on purpose\n\
STEP 15: Restart any stopped SP.\n\
\n\
Description Last Updated: 5/15/2012\n\
\n";

/*!*******************************************************************
 * @def EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT
 *********************************************************************
 * @brief IO block count for only drive, or spilled over onto 2nd drive.
 *
 *********************************************************************/
#define EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT 0x10

/*!*******************************************************************
 * @def EDGAR_THE_BUG_RAID_TYPE_COUNT
 *********************************************************************
 * @brief Number of separate raid config type groups we will setup.
 *
 *********************************************************************/
#define EDGAR_THE_BUG_RAID_TYPE_COUNT 3

/*!*******************************************************************
 * @def EDGAR_THE_BUG_RAID_CONFIG_PER_TYPE_COUNT
 *********************************************************************
 * @brief Max number of separate configs per type we will setup.
 *
 *********************************************************************/
#define EDGAR_THE_BUG_RAID_CONFIG_PER_TYPE_COUNT 4

/*!*******************************************************************
 * @def EDGAR_THE_BUG_LUNS_PER_RAID_GROUP
 *********************************************************************
 * @brief luns per rg for the extended test. 
 *
 *********************************************************************/
#define EDGAR_THE_BUG_LUNS_PER_RAID_GROUP 1

/*!*******************************************************************
 * @def EDGAR_THE_BUG_CHUNKS_PER_LUN
 *********************************************************************
 * @brief Number of chunks each LUN will occupy.
 *
 *********************************************************************/
#define EDGAR_THE_BUG_CHUNKS_PER_LUN 3

/*!*******************************************************************
 * @def EDGAR_THE_BUG_WAIT_MSEC
 *********************************************************************
 * @brief Number of milliseconds we should wait for state changes.
 *        We set this relatively large so that if we do exceed this
 *        we will be sure something is wrong.
 *
 *********************************************************************/
#define EDGAR_THE_BUG_WAIT_MSEC 1000 * 120

/*!*******************************************************************
 * @def FBE_API_POLLING_INTERVAL
 *********************************************************************
 * @brief Number of milliseconds we should wait to poll the SP
 *
 *********************************************************************/
#define FBE_API_POLLING_INTERVAL 100 /*ms*/

/*!*******************************************************************
 * @def EDGAR_THE_BUG_THREAD_COUNT
 *********************************************************************
 * @brief The number of threads to run io in during the test
 *
 *********************************************************************/
#define EDGAR_THE_BUG_THREAD_COUNT 32

/*!*******************************************************************
 * @def EDGAR_THE_BUG_ACTIVE_SP
 *********************************************************************
 * @brief The active SP 
 *
 *********************************************************************/
#define EDGAR_THE_BUG_ACTIVE_SP FBE_SIM_SP_A

/*!*******************************************************************
 * @def EDGAR_THE_BUG_PASSIVE_SP
 *********************************************************************
 * @brief The passive SP 
 *
 *********************************************************************/
#define EDGAR_THE_BUG_PASSIVE_SP FBE_SIM_SP_B

/*!*******************************************************************
 * @var edgar_the_bug_test_contexts
 *********************************************************************
 * @brief This contains our context objects for running rdgen I/O.
 *
 *********************************************************************/
static fbe_api_rdgen_context_t edgar_the_bug_test_contexts[EDGAR_THE_BUG_RAID_CONFIG_PER_TYPE_COUNT][2];


/*!*******************************************************************
 * @var rg_object_id
 *********************************************************************
 * @brief A handy array for remembering rg_object_ids.
 *
 *********************************************************************/
fbe_object_id_t rg_object_id[EDGAR_THE_BUG_RAID_CONFIG_PER_TYPE_COUNT];

/*!*******************************************************************
 * @var edgar_the_bug_raid_group_config_qual
 *********************************************************************
 * @brief This is the array of configurations we will loop over.
 *
 *********************************************************************/
#ifdef ALAMOSA_WINDOWS_ENV
fbe_test_rg_configuration_array_t edgar_the_bug_raid_group_config_qual[EDGAR_THE_BUG_RAID_TYPE_COUNT + 1] = 
#else
fbe_test_rg_configuration_array_t edgar_the_bug_raid_group_config_qual[] = 
#endif /* ALAMOSA_WINDOWS_ENV - ODDCASE - shrink table/executable size */
{
    /* IMPORTANT NOTE: Because only one error record is set up for all configs in a raid type,
     *    and that error record includes an lba limit which we want to be less than the metadata lba
     *    the small (bandwidth = 0) configs must have enough user space to fit an element of the largest
     *    (bandwidth = 1) configs.  This means at least FBE_RAID_SECTORS_PER_ELEMENT_BANDWIDTH sectors */
    /* Raid 5 configurations -- test can use 3 disks or more, with 4 or more it will do a 2 drive IO.
     */
    {
        /* width, capacity     raid type,                  class,                  block size      RAID-id.   bandwidth.*/
        {3,       0xE000,      FBE_RAID_GROUP_TYPE_RAID5,  FBE_CLASS_ID_PARITY,    520,            0,         0},
        {4,       0xE000,      FBE_RAID_GROUP_TYPE_RAID5,  FBE_CLASS_ID_PARITY,    520,            1,         0},
        {5,       0xE000,      FBE_RAID_GROUP_TYPE_RAID5,  FBE_CLASS_ID_PARITY,    520,            2,         1},
        {16,      0xE000,      FBE_RAID_GROUP_TYPE_RAID5,  FBE_CLASS_ID_PARITY,    520,            3,         0},
        {FBE_U32_MAX, FBE_U32_MAX, FBE_U32_MAX, /* Terminator. */},
    },
    /* Raid 3 configurations -- test can use 3 disks or more, with 4 or more it will do a 2 drive IO.
     * But minimum Raid 3 is 5 disks (4 for vaults), max 9, and must be exactly min or max or vault...
     */
    {
        /* width, capacity     raid type,                  class,                  block size      RAID-id.   bandwidth.*/
        {5,       0xE000,      FBE_RAID_GROUP_TYPE_RAID3,  FBE_CLASS_ID_PARITY,    520,            0,         0},
        {5,       0xE000,      FBE_RAID_GROUP_TYPE_RAID3,  FBE_CLASS_ID_PARITY,    520,            1,         1},
        {9,       0xE000,      FBE_RAID_GROUP_TYPE_RAID3,  FBE_CLASS_ID_PARITY,    520,            2,         0},
        {FBE_U32_MAX, FBE_U32_MAX, FBE_U32_MAX, /* Terminator. */},
    },
    /* Raid 6 configurations -- test can use 5 disks or more, with 6 or more it will do a 2 drive IO.
     * Minimum Raid 6 is 4 drives, and width must be even number
     */
    {
        /* width, capacity     raid type,                  class,                  block size      RAID-id.   bandwidth.*/
        {6,       0xE000,      FBE_RAID_GROUP_TYPE_RAID6,  FBE_CLASS_ID_PARITY,    520,            0,         0},
        {6,       0xE000,      FBE_RAID_GROUP_TYPE_RAID6,  FBE_CLASS_ID_PARITY,    520,            1,         1},
        {16,      0xE000,      FBE_RAID_GROUP_TYPE_RAID6,  FBE_CLASS_ID_PARITY,    520,            2,         0},
        {FBE_U32_MAX, FBE_U32_MAX, FBE_U32_MAX, /* Terminator. */},
    },
    {FBE_U32_MAX, FBE_U32_MAX, FBE_U32_MAX, /* Terminator. */},
};
/**************************************
 * end edgar_the_bug_raid_group_config_qual
 **************************************/

/*!*******************************************************************
 * @var edgar_the_bug_temp_array
 *********************************************************************
 * @brief This is a temp array of configurations we use to reboot peer
 *        without overwriting the original array.
 *
 *********************************************************************/

/* Had to allocate this here instead of on the restart_peer call stack (as other tests do) because
 *  this is an array of configs, and was too big for the stack.
 */
fbe_test_rg_configuration_array_t edgar_the_bug_temp_array[EDGAR_THE_BUG_RAID_TYPE_COUNT + 1];

/**************************************
 * end edgar_the_bug_temp_array
 **************************************/

/* LEI Record to create to delay the IO going down the stack
 * Delay position is always drive 2 so it's a data drive even with 2 parity drives.
 *   since we only get one error injection record, the position must be width and raid type independent
 */
fbe_api_logical_error_injection_record_t edgar_the_bug_record_down =        
{ 0x4,  /* pos_bitmap = 0x1 << delay position (0x1 << 2) */
    0x10, /* width */
    0x0,  /* lba */
    FBE_RAID_SECTORS_PER_ELEMENT_BANDWIDTH,  /* max number of blocks in an element, to get every io to first stripe */
    FBE_API_LOGICAL_ERROR_INJECTION_TYPE_DELAY_IO_DOWN,  /* error type */
    FBE_API_LOGICAL_ERROR_INJECTION_MODE_ALWAYS,         /* error mode */
    0x0,  /* error count */
    FBE_LOGICAL_ERROR_INJECTION_MAX_DELAY_MS, /* error limit is msec to delay*/
    0x0,  /* skip count */
    0x15, /* skip limit */
    0x1,  /* error adjacency */
    0x0,  /* start bit */
    0x0,  /* number of bits */
    0x0,  /* erroneous bits */
    0x0,  /* crc detectable */
    FBE_PAYLOAD_BLOCK_OPERATION_OPCODE_WRITE};   /* opcode */

/*!*******************************************************************
 * @def edgar_the_bug_test_case_t
 *********************************************************************
 * @brief Test sequence struct to pass in to tests
 *
 *********************************************************************/
typedef struct edgar_the_bug_test_case_s
{
    fbe_sim_transport_connection_target_t target_sp;
    fbe_bool_t b_quick_restart;
    fbe_bool_t b_restart_to_active;
    fbe_bool_t b_test_invalidated_write;
}edgar_the_bug_test_case_t;



/*!*******************************************************************
 * @var edgar_the_bug_test_case_array
 *********************************************************************
 * @brief The array of test cases to run on each raid type.
 *
 *********************************************************************/
edgar_the_bug_test_case_t edgar_the_bug_test_case_array[] =
{
#if 0 /* Removed to shorten test -- effect should be the same as {EDGAR_THE_BUG_XXXX_SP, FBE_TRUE, FBE_FALSE, FBE_FALSE} */
    {EDGAR_THE_BUG_ACTIVE_SP, FBE_FALSE, FBE_FALSE, FBE_FALSE},
    {EDGAR_THE_BUG_PASSIVE_SP, FBE_FALSE, FBE_FALSE, FBE_FALSE},
#endif
    {EDGAR_THE_BUG_ACTIVE_SP, FBE_TRUE, FBE_FALSE, FBE_FALSE},
    {EDGAR_THE_BUG_PASSIVE_SP, FBE_TRUE, FBE_FALSE, FBE_FALSE},
    {EDGAR_THE_BUG_ACTIVE_SP, FBE_TRUE, FBE_TRUE, FBE_FALSE},
    {EDGAR_THE_BUG_PASSIVE_SP, FBE_TRUE, FBE_TRUE, FBE_FALSE},
    {EDGAR_THE_BUG_ACTIVE_SP, FBE_FALSE, FBE_FALSE, FBE_TRUE}, /* Test invalidate write handling */
    {FBE_SIM_INVALID_SERVER, FBE_FALSE, FBE_FALSE, FBE_FALSE}
};

void edgar_the_bug_run_tests_in_parallel(fbe_test_rg_configuration_t *rg_config_p,
                                         fbe_sim_transport_connection_target_t target_sp,
                                         fbe_bool_t b_quick_restart,
                                         fbe_bool_t b_restart_to_active,
                                         fbe_bool_t b_test_invalidated_write);

void edgar_the_bug_run_test_config(fbe_test_rg_configuration_t *rg_config_p, void *test_case);

static void edgar_the_bug_set_test_params(fbe_test_rg_configuration_t *rg_config_p,
                                          fbe_u32_t *block_count,
                                          fbe_lba_t *lba,
                                          fbe_u32_t *num_to_remove,
                                          fbe_test_event_log_test_result_t *log_expected_result,
                                          fbe_test_event_log_test_result_t *log_unexpected_result)
{
    log_expected_result->num_msgs = 0;
    log_unexpected_result->num_msgs = 0;

    /* Note that parity is drive 0 or 0 and 1, and lba 0 starts at the last drive (width - 1)
     *  and that the delay drive is always drive 2 for all raid groups
     */
    switch (rg_config_p->raid_type)
    {
    case FBE_RAID_GROUP_TYPE_RAID3:
    case FBE_RAID_GROUP_TYPE_RAID5:
    default:
        {
            *num_to_remove = 1;
            if (rg_config_p->width > 3)
            {
                /* kill the last drive and start the io on delayed drive 2, and continue into drive 1
                */
                rg_config_p->specific_drives_to_remove[0] = rg_config_p->width - 1;

                if (rg_config_p->b_bandwidth)
                {
                    *block_count = FBE_RAID_SECTORS_PER_ELEMENT_BANDWIDTH + EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT;
                    *lba = (rg_config_p->width - 3) * FBE_RAID_SECTORS_PER_ELEMENT_BANDWIDTH;
                }
                else
                {
                    *block_count = FBE_RAID_SECTORS_PER_ELEMENT + EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT;
                    *lba = (rg_config_p->width - 3) * FBE_RAID_SECTORS_PER_ELEMENT;
                }

                {
                    fbe_test_event_log_test_result_t local_result =
                    {
                        0x6,  /* number of expected event log messages */
                        {
                            {   /* the rebuild error on 1st drive shared region */ 
                                2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT  /* expected blocks */
                            },
                            {   /* the rebuild invalidated on 1st drive shared region*/ 
                                2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT  /* expected blocks */
                            },
                            {   /* the rebuild error on 2nd drive */ 
                                1, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT  /* expected blocks */
                            },
                            {   /* the rebuild invalidated on 2nd drive */ 
                                1, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT  /* expected blocks */
                            },
                            {   /* the rebuild error on 1st drive only region */ 
                                2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT, /* expected lba */
                                *block_count - (2 * EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT)  /* expected blocks */
                            },
                            {   /* the rebuild invalidated on 1st drive only region*/ 
                                2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT, /* expected lba */
                                *block_count - (2 * EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT)  /* expected blocks */
                            },
                        }
                    };
                    *log_expected_result = local_result;
                }
                {
                    fbe_test_event_log_test_result_t local_result =
                    {
                        0x4,  /* number of unexpected event log messages */
                        {
                            {   /* no flush log abandoned */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected fru position */ 
                                SEP_INFO_RAID_PARITY_WRITE_LOG_FLUSH_ABANDONED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no parity errors */
                                0, /* expected fru position */ 
                                SEP_INFO_RAID_HOST_PARITY_SECTOR_RECONSTRUCTED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                rg_config_p->width - 1, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                rg_config_p->width - 1, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                        }
                    };
                    *log_unexpected_result = local_result;
                }
            }
            else
            {
                /* kill drive 1 and do a small io on delayed drive 2
                */
                rg_config_p->specific_drives_to_remove[0] = 1;
                *block_count = EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT;
                *lba = 0;

                {
                    fbe_test_event_log_test_result_t local_result =
                    {
                        0x2,  /* number of expected event log messages */
                        {
                            {   /* the rebuild error on 1st drive only region */ 
                                2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                *block_count  /* expected blocks */
                            },
                            {   /* the rebuild invalidated on 1st drive only region*/ 
                                2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                *block_count  /* expected blocks */
                            },
                        }
                    };
                    *log_expected_result = local_result;
                }
                {
                    fbe_test_event_log_test_result_t local_result =
                    {
                        0x4,  /* number of unexpected event log messages */
                        {
                            {   /* no flush log abandoned */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected fru position */ 
                                SEP_INFO_RAID_PARITY_WRITE_LOG_FLUSH_ABANDONED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no parity errors */
                                0, /* expected fru position */ 
                                SEP_INFO_RAID_HOST_PARITY_SECTOR_RECONSTRUCTED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                1, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                1, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                        }
                    };
                    *log_unexpected_result = local_result;
                }
            }
            break;
        }
    case FBE_RAID_GROUP_TYPE_RAID6:
        {
            /* always kill the last two drives
             */
            *num_to_remove = 2;
            rg_config_p->specific_drives_to_remove[0] = rg_config_p->width - 2;
            rg_config_p->specific_drives_to_remove[1] = rg_config_p->width - 1;

            if (rg_config_p->width > 6)
            {
                /* start the io on drive 3, and continue into delayed drive 2
                */
                if (rg_config_p->b_bandwidth)
                {
                    *block_count = FBE_RAID_SECTORS_PER_ELEMENT_BANDWIDTH + EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT;
                    *lba = (rg_config_p->width - 4) * FBE_RAID_SECTORS_PER_ELEMENT_BANDWIDTH;
                }
                else
                {
                    *block_count = FBE_RAID_SECTORS_PER_ELEMENT + EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT;
                    *lba = (rg_config_p->width - 4) * FBE_RAID_SECTORS_PER_ELEMENT;
                }
                {
                    fbe_test_event_log_test_result_t local_result =
                    {
                        0x6,  /* number of expected event log messages */
                        {
                            {   /* the rebuild error on 1st drive shared region */ 
                                3, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT  /* expected blocks */
                            },
                            {   /* the rebuild invalidated on 1st drive shared region*/ 
                                3, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT  /* expected blocks */
                            },
                            {   /* the rebuild error on 2nd drive */ 
                                2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT  /* expected blocks */
                            },
                            {   /* the rebuild invalidated on 2nd drive */ 
                                2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT  /* expected blocks */
                            },
                            {   /* the rebuild error on 1st drive only region */ 
                                3, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT, /* expected lba */
                                *block_count - (2 * EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT)  /* expected blocks */
                            },
                            {   /* the rebuild invalidated on 1st drive only region*/ 
                                3, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT, /* expected lba */
                                *block_count - (2 * EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT)  /* expected blocks */
                            },
                        }
                    };
                    *log_expected_result = local_result;
                }
                {
                    fbe_test_event_log_test_result_t local_result =
                    {
                        0x7,  /* number of unexpected event log messages */
                        {
                            {   /* no flush log abandoned */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected fru position */ 
                                SEP_INFO_RAID_PARITY_WRITE_LOG_FLUSH_ABANDONED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no parity errors */
                                0, /* expected fru position */ 
                                SEP_INFO_RAID_HOST_PARITY_SECTOR_RECONSTRUCTED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no parity errors */
                                1, /* expected fru position */ 
                                SEP_INFO_RAID_HOST_PARITY_SECTOR_RECONSTRUCTED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                rg_config_p->width - 1, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                rg_config_p->width - 1, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                rg_config_p->width - 2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                rg_config_p->width - 2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                        }
                    };
                    *log_unexpected_result = local_result;
                }
            }
            else
            {
                /* do a small io on delayed drive 2
                */
                *block_count = EDGAR_THE_BUG_MIN_IO_BLOCK_COUNT;
                if (rg_config_p->b_bandwidth)
                {
                    *lba = (rg_config_p->width - 3) * FBE_RAID_SECTORS_PER_ELEMENT_BANDWIDTH;
                }
                else
                {
                    *lba = (rg_config_p->width - 3) * FBE_RAID_SECTORS_PER_ELEMENT;
                }
                {
                    fbe_test_event_log_test_result_t local_result =
                    {
                        0x2,  /* number of expected event log messages */
                        {
                            {   /* the rebuild error on 1st drive only region */ 
                                2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                *block_count  /* expected blocks */
                            },
                            {   /* the rebuild invalidated on 1st drive only region*/ 
                                2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                VR_INVALID_CRC, /* expected error info */
                                0x0, /* expected lba */
                                *block_count  /* expected blocks */
                            },
                        }
                    };
                    *log_expected_result = local_result;
                }
                {
                    fbe_test_event_log_test_result_t local_result =
                    {
                        0x7,  /* number of unexpected event log messages */
                        {
                            {   /* no flush log abandoned */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected fru position */ 
                                SEP_INFO_RAID_PARITY_WRITE_LOG_FLUSH_ABANDONED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no parity errors */
                                0, /* expected fru position */ 
                                SEP_INFO_RAID_HOST_PARITY_SECTOR_RECONSTRUCTED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no parity errors */
                                1, /* expected fru position */ 
                                SEP_INFO_RAID_HOST_PARITY_SECTOR_RECONSTRUCTED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                rg_config_p->width - 1, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                rg_config_p->width - 1, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                rg_config_p->width - 2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                            {   /* no dead drive errors */ 
                                rg_config_p->width - 2, /* expected fru position */ 
                                SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED, /* expected error code */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected error info */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD, /* expected lba */
                                MUMFORD_THE_MAGICIAN_TEST_WILD_CARD  /* expected blocks */
                            },
                        }
                    };
                    *log_unexpected_result = local_result;
                }
            }
            break;
        }
    }
}

/*!***************************************************************************
 * edgar_the_bug_verify_write_log_flushed()
 *****************************************************************************
 * @brief Check the readable on-disk write log headers that there are no headers still valid.
 *
 * @param rg_object_id - Raid group to check.
 * @param b_chk_remap - if true, check that write_log slots are remapped
 * @param slot_id - slot_id to check. If invalid slot_id, check all slots.
 * @param b_flushed_p - FBE_TRUE if headers are flushed/remapped, FBE_FALSE otherwise.  
 *
 * @return fbe_status_t - FBE_STATUS_OK if operation succeeded, error if not;
                          Note that a dead disk or media error is not considered an error 
 *
 * @author
 *  07/13/2012 - Created. Dave Agans
 *
 *****************************************************************************/
fbe_status_t edgar_the_bug_verify_write_log_flushed(fbe_object_id_t rg_object_id, fbe_bool_t b_chk_remap, 
                                                    fbe_u32_t slot_id, fbe_bool_t *b_flushed_p)
{
    fbe_status_t                                status = FBE_STATUS_OK;
    fbe_database_raid_group_info_t              rg_info;
    fbe_u8_t *                                  slot_buffer_p = NULL;
    fbe_sg_element_t                            sg_elements[FBE_DATA_PATTERN_MAX_SG_DATA_ELEMENTS+1] = {0}; 
    fbe_sg_element_t *                          sg_ptr = NULL;
    fbe_parity_get_write_log_info_t             write_log_info;
    fbe_u32_t                                   current_slot_id = FBE_PARITY_WRITE_LOG_INVALID_SLOT;
    fbe_u32_t                                   start_slot_id = FBE_PARITY_WRITE_LOG_INVALID_SLOT;
    fbe_u32_t                                   end_slot_id = FBE_PARITY_WRITE_LOG_INVALID_SLOT;
    fbe_parity_get_write_log_slot_t *           slot_p;
    fbe_lba_t                                   lba;
    fbe_object_id_t                             disk_id;
    fbe_u32_t                                   current_disk_index;
    fbe_block_size_t                            optimal_block_size = 1;
    fbe_payload_block_operation_t               block_operation;
    fbe_block_transport_block_operation_info_t  block_operation_info = {0};
    fbe_parity_write_log_header_t *             header_p;
    fbe_block_count_t                           block_count;
    fbe_u8_t                                    zero_buff[FBE_BYTES_PER_BLOCK];
    fbe_u32_t                                   idx;
    fbe_lifecycle_state_t                       current_state = FBE_LIFECYCLE_STATE_NOT_EXIST;

    /* Get the raid group info so we can check the raid type and walk the disk objects
     */
    status = fbe_api_database_get_raid_group(rg_object_id, &rg_info);
    if (status != FBE_STATUS_OK)
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: could not get raid group 0x%x info.\n",
                   rg_object_id);
        return status;
    }

    /* Verify that this is a parity before barging on ahead
     */
    if (   rg_info.rg_info.raid_type != FBE_RAID_GROUP_TYPE_RAID3
        && rg_info.rg_info.raid_type != FBE_RAID_GROUP_TYPE_RAID5
        && rg_info.rg_info.raid_type != FBE_RAID_GROUP_TYPE_RAID6)
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Raid group id: 0x%x is not a parity, and thus has no write log\n",
                   rg_object_id);
        return FBE_STATUS_INVALID;
    }

    /* Get the slot info from the raid group
     */
    status = fbe_api_raid_group_get_write_log_info(rg_object_id,
                                                   &write_log_info, 
                                                   FBE_PACKET_FLAG_NO_ATTRIB);
    if (status != FBE_STATUS_OK)
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Not able to get the write log information for RG object id 0x%x\n", 
                   rg_object_id);
        return status;
    }

    if (b_chk_remap)
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== Verifying write log remapped for raid group 0x%x\n", 
                   rg_object_id);
        block_count = write_log_info.slot_size;
        fbe_zero_memory(&zero_buff, FBE_BYTES_PER_BLOCK);
    }
    else
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== Verifying write log flushed for raid group 0x%x\n", 
                   rg_object_id);
        block_count = write_log_info.header_size; /* header size in blocks */
    }

    /* Initialize the b_flushed result to TRUE, we will set it FALSE if we find a valid header
     */
    *b_flushed_p = FBE_TRUE;

    /* Allocate a buffer.
     */
    slot_buffer_p = (fbe_u8_t *)fbe_api_allocate_memory((fbe_u32_t)block_count * FBE_BE_BYTES_PER_BLOCK);

    if (slot_buffer_p == NULL)
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Could not allocate a buffer\n");
        return FBE_STATUS_INVALID;
    }

    /* Set up the sg_ptr to use the SG list
     */
    sg_ptr = sg_elements;

    status = fbe_data_pattern_sg_fill_with_memory(sg_ptr,
                                                  slot_buffer_p,
                                                  block_count,   
                                                  FBE_BE_BYTES_PER_BLOCK,
                                                  FBE_DATA_PATTERN_MAX_SG_DATA_ELEMENTS,
                                                  FBE_DATA_PATTERN_MAX_BLOCKS_PER_SG);
    if (status != FBE_STATUS_OK)
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Setting up sg failed.\n");
        fbe_api_free_memory(slot_buffer_p);
        return status;
    }

    /* Set slot ids that need to be verified. */
    if (slot_id == FBE_PARITY_WRITE_LOG_INVALID_SLOT)
    {
        start_slot_id = 0;
        end_slot_id = write_log_info.slot_count;
    }
    else
    {
        start_slot_id = slot_id;
        end_slot_id = slot_id + 1;
    }

    /* Walk each slot
     */
    for (current_slot_id = start_slot_id; current_slot_id < end_slot_id; current_slot_id++)
    {
        slot_p = &write_log_info.slot_array[current_slot_id];

        if (b_chk_remap)
        {
            /* Check that the in-memory slot is free. Flush and Remap operations should be completed by now. 
             */
            if (!(slot_p->state == FBE_PARITY_WRITE_LOG_SLOT_STATE_FREE))
            {
                *b_flushed_p = FBE_FALSE;
                mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Found non-free slot for object_id:0x%x slot:0x%x state:0x%x\n", 
                           rg_object_id, 
                           current_slot_id,
                           slot_p->state);
                fbe_api_free_memory(slot_buffer_p);
                return FBE_STATUS_OK;
            }
        }
        else
        {
            /* Check that the in-memory slot is either free or marked for remap. 
             */
            if (!((slot_p->state == FBE_PARITY_WRITE_LOG_SLOT_STATE_FREE) ||
                  (slot_p->state == FBE_PARITY_WRITE_LOG_SLOT_STATE_ALLOCATED_FOR_REMAP) ||
                  (slot_p->state == FBE_PARITY_WRITE_LOG_SLOT_STATE_REMAPPING)))
            {
                *b_flushed_p = FBE_FALSE;
                mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Found non-free/non-remap slot for object_id:0x%x slot:0x%x state:0x%x\n", 
                           rg_object_id, 
                           current_slot_id,
                           slot_p->state);
                MUT_ASSERT_TRUE(FBE_FALSE);
                fbe_api_free_memory(slot_buffer_p);
                return FBE_STATUS_OK;
            }
        }

        /* Get the slot lba based on the slot number
         */
        lba =   rg_info.rg_info.physical_offset
              + rg_info.rg_info.write_log_start_pba
              + (current_slot_id * write_log_info.slot_size);

        /* Walk each disk
         */
        for (current_disk_index = 0; current_disk_index < rg_info.pvd_count; current_disk_index++)
        {
            /* Get the object ID and do the read
             */
            disk_id = rg_info.pvd_list[current_disk_index];

            if (disk_id != FBE_OBJECT_ID_INVALID)
            {
                /* Wait for PVD to become READY */
                status = fbe_api_get_object_lifecycle_state(disk_id, &current_state, FBE_PACKAGE_ID_SEP_0);
                MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);

                if (current_state != FBE_LIFECYCLE_STATE_READY) 
                {
                    rg_info.pvd_list[current_disk_index] = FBE_OBJECT_ID_INVALID; /* Avoid future scan */
                    status = FBE_STATUS_OK; /* This is a removed drive */
                    mut_printf(MUT_LOG_TEST_STATUS, "== PVD 0x%x is not READY \n", disk_id);
                    continue;
                }
                /* Build the block operation and attach it to the block_operation_info
                 */
                status = fbe_payload_block_build_operation(&block_operation,
                                                           FBE_PAYLOAD_BLOCK_OPERATION_OPCODE_READ,
                                                           lba,
                                                           block_count,
                                                           FBE_BE_BYTES_PER_BLOCK,
                                                           optimal_block_size,
                                                           NULL);
                if (status != FBE_STATUS_OK)
                {
                    mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Block operation build failed for raid group 0x%x\n", 
                               rg_object_id);
                    fbe_api_free_memory(slot_buffer_p);
                    return status;
                }
                block_operation_info.block_operation = block_operation;

                //mut_printf(MUT_LOG_TEST_STATUS, "== Verify write_log: sending block op to rg_id: 0x%x, width: 0x%x, pos: 0x%x, pvd_id: 0x%x, slot_id 0x%x blk_cnt 0x%x \n", 
                           //rg_object_id, rg_info.pvd_count, current_disk_index, disk_id, current_slot_id, block_count);

                /* This is wrong API! we should send packet and not bloc operation */
                status = fbe_api_block_transport_send_block_operation(disk_id,
                                                                      FBE_PACKAGE_ID_SEP_0,
                                                                      &block_operation_info,
                                                                      (fbe_sg_element_t*)sg_ptr);
                if (status != FBE_STATUS_OK)
                {
                    mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Block operation failed to object_id: %d pkt_status: 0x%x\n", 
                               disk_id, 
                               status);
                    fbe_api_free_memory(slot_buffer_p);
                    return status;
                }

                block_operation = block_operation_info.block_operation;

                if (block_operation.status == FBE_PAYLOAD_BLOCK_OPERATION_STATUS_SUCCESS)
                {
                    if (b_chk_remap)
                    {
                        fbe_u8_t * temp_buffer_p = slot_buffer_p;
                        for (idx = 0; idx < block_count; idx++)
                        {
                            if (!fbe_equal_memory(&zero_buff, temp_buffer_p, FBE_BYTES_PER_BLOCK))
                            {
                                *b_flushed_p = FBE_FALSE;
                                mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Remap not successful for object_id:0x%x slot:0x%x drive:0x%x\n", 
                                           rg_object_id, 
                                           current_slot_id,
                                           current_disk_index);
                                fbe_api_free_memory(slot_buffer_p);
                                return FBE_STATUS_OK;
                            }
                            temp_buffer_p += (FBE_BE_BYTES_PER_BLOCK / sizeof(fbe_u8_t));
                        }
                    }
                    else
                    {
                        /* Point the header to the block and check it, see if any are valid
                         */
                        header_p = (fbe_parity_write_log_header_t *)slot_buffer_p;

                        /*!@todo When there are more than one version, need to accept any version here 
                         */
                        if (   header_p->header_state == FBE_PARITY_WRITE_LOG_HEADER_STATE_VALID
                               && header_p->header_version == FBE_PARITY_WRITE_LOG_CURRENT_HEADER_VERSION)
                        {
                            *b_flushed_p = FBE_FALSE;
                            mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Found valid header for object_id:0x%x slot:0x%x drive:0x%x\n", 
                                       rg_object_id, 
                                       current_slot_id,
                                       current_disk_index);
                            fbe_api_free_memory(slot_buffer_p);
                            return FBE_STATUS_OK;
                        }
                    }
                }
            }
        }
    }

    fbe_api_free_memory(slot_buffer_p);
    return status;
}

/*!***************************************************************************
 * edgar_the_bug_zero_write_log_slot()
 *****************************************************************************
 * @brief Initialize on-disk write log slots.
 *
 * @param rg_object_id - Raid group to check.
 * @param slot_id - slot_id to check. If invalid slot_id, initialize all slots.  
 *
 * @return fbe_status_t - FBE_STATUS_OK if operation succeeded, error if not.
 *
 * @author
 *  08/16/2012 - Created. Vamsi V.
 *
 *****************************************************************************/
fbe_status_t edgar_the_bug_zero_write_log_slot(fbe_object_id_t rg_object_id, fbe_u32_t slot_id)
{
    fbe_status_t status = FBE_STATUS_OK;
    fbe_database_raid_group_info_t rg_info;
    fbe_u8_t* slot_buffer_p = NULL;
    fbe_sg_element_t  sg_elements[FBE_DATA_PATTERN_MAX_SG_DATA_ELEMENTS+1] = {0}; 
    fbe_sg_element_t  *sg_ptr = NULL;
    fbe_lba_t         lba;
    fbe_object_id_t   disk_id;
    fbe_u32_t         current_disk_index;
    fbe_block_size_t   optimal_block_size = 1;
    fbe_payload_block_operation_t   block_operation;
    fbe_block_transport_block_operation_info_t  block_operation_info = {0};
    fbe_parity_get_write_log_info_t             write_log_info;

    mut_printf(MUT_LOG_TEST_STATUS, "== Zeroing write log slot 0x%x for raid group 0x%x\n", 
               slot_id, rg_object_id);

    /* Get the raid group info so we can walk the disks objects
     */
    status = fbe_api_database_get_raid_group(rg_object_id, &rg_info);
    if (status != FBE_STATUS_OK)
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: could not get raid group 0x%x info.\n",
                   rg_object_id);
        return status;
    }

    /* Verify that this is a parity before barging on ahead
     */
    if (   rg_info.rg_info.raid_type != FBE_RAID_GROUP_TYPE_RAID3
        && rg_info.rg_info.raid_type != FBE_RAID_GROUP_TYPE_RAID5
        && rg_info.rg_info.raid_type != FBE_RAID_GROUP_TYPE_RAID6)
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Raid group id: 0x%x is not a parity, and thus has no write log\n",
                   rg_object_id);
        return FBE_STATUS_INVALID;
    }

    /* Get the slot info from the raid group
     */
    status = fbe_api_raid_group_get_write_log_info(rg_object_id,
                                                   &write_log_info, 
                                                   FBE_PACKET_FLAG_NO_ATTRIB);
    if (status != FBE_STATUS_OK)
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Not able to get the write log information for RG object id 0x%x\n", 
                   rg_object_id);
        return status;
    }

    /* Allocate a buffer.
     */
    slot_buffer_p = (fbe_u8_t *)fbe_api_allocate_memory(write_log_info.slot_size * FBE_BE_BYTES_PER_BLOCK);
    if (slot_buffer_p)
    {
        fbe_zero_memory(slot_buffer_p, write_log_info.slot_size * FBE_BE_BYTES_PER_BLOCK);
    }
    else
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Could not allocate a buffer\n");
        return FBE_STATUS_INVALID;
    }

    /* Initialize write buffer */
    {
        fbe_u16_t           metadata_size = 0;
        fbe_u64_t           zero_metadata = 0x7fff5eed;
        fbe_u8_t *          data_buffer_p = NULL;
        fbe_block_count_t   block_count;

        data_buffer_p = slot_buffer_p;

        /* get the number of blocks from the zero bit bucket size. */
        block_count = write_log_info.slot_size;
        metadata_size = 8;

        /* Fill out the data buffer with valid zero buffer. */
        while (block_count != 0)
        {
            data_buffer_p += FBE_BYTES_PER_BLOCK;
            fbe_copy_memory(data_buffer_p, (void *) &zero_metadata, metadata_size);
            data_buffer_p += metadata_size;
            block_count--;
        }
    }

    /* Set up the sg_ptr to use the SG list
     */
    sg_ptr = sg_elements;

    status = fbe_data_pattern_sg_fill_with_memory(sg_ptr,
                                                  slot_buffer_p,
                                                  write_log_info.slot_size,
                                                  FBE_BE_BYTES_PER_BLOCK,
                                                  FBE_DATA_PATTERN_MAX_SG_DATA_ELEMENTS,
                                                  FBE_DATA_PATTERN_MAX_BLOCKS_PER_SG);
    if (status != FBE_STATUS_OK)
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Setting up sg failed.\n");
        fbe_api_free_memory(slot_buffer_p);
        return status;
    }

    /* Get the slot lba based on the slot number
     */
    lba =   rg_info.rg_info.physical_offset
          + rg_info.rg_info.write_log_start_pba
          + (slot_id * write_log_info.slot_size);

    /* Walk each disk
     */
    for (current_disk_index = 0; current_disk_index < rg_info.pvd_count; current_disk_index++)
    {
        /* Get the object ID and do the read
         */
        disk_id = rg_info.pvd_list[current_disk_index];

        if (disk_id != FBE_OBJECT_ID_INVALID)
        {
            /* Build the block operation and attach it to the block_operation_info
             */
            status = fbe_payload_block_build_operation(&block_operation,
                                                       FBE_PAYLOAD_BLOCK_OPERATION_OPCODE_WRITE,
                                                       lba,
                                                       write_log_info.header_size, /* header size in blocks*/
                                                       FBE_BE_BYTES_PER_BLOCK,
                                                       optimal_block_size,
                                                       NULL);
            if (status != FBE_STATUS_OK)
            {
                mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Block operation build failed for raid group 0x%x\n", 
                           rg_object_id);
                fbe_api_free_memory(slot_buffer_p);
                return status;
            }
            block_operation_info.block_operation = block_operation;

            /* This is wrong API! we should send packet and not bloc operation */
            status = fbe_api_block_transport_send_block_operation(
                                                                 disk_id,
                                                                 FBE_PACKAGE_ID_SEP_0,
                                                                 &block_operation_info,
                                                                 (fbe_sg_element_t*)sg_ptr);
            if (status != FBE_STATUS_OK)
            {
                mut_printf(MUT_LOG_TEST_STATUS, "== ERROR: Block operation failed to object_id: %d pkt_status: 0x%x\n", 
                           disk_id, 
                           status);
                fbe_api_free_memory(slot_buffer_p);
                return status;
            }

            block_operation = block_operation_info.block_operation;
            MUT_ASSERT_INT_EQUAL(block_operation.status, FBE_PAYLOAD_BLOCK_OPERATION_STATUS_SUCCESS);
        }
    }

    fbe_api_free_memory(slot_buffer_p);
    return status;
}

/*!**************************************************************
 * edgar_the_bug_get_msg_count_relevant_to_error()
 ****************************************************************
 * @brief 
 * Gets total number of event log messages in event log which
 * are as a result of reporting of sector error messages by 
 * RAID group object.
 *
 * @return number of event log message(s)
 *
 * @author
 *  01/18/2011 - Jyoti Ranjan Created
 *
 ****************************************************************/
fbe_u32_t edgar_the_bug_get_msg_count_relevant_to_error(void)
{
    fbe_status_t status;
    fbe_u32_t message_count = 0;
    fbe_u32_t event_log_index;
    fbe_event_log_statistics_t event_log_statistics = { 0};
    fbe_event_log_get_event_log_info_t event_log = {0};

    status = fbe_api_get_event_log_statistics(&event_log_statistics,FBE_PACKAGE_ID_SEP_0);
    MUT_ASSERT_TRUE_MSG(status == FBE_STATUS_OK, "== Error: failed to get event log statistics == \n");

    for (event_log_index = 0; event_log_index < event_log_statistics.total_msgs_logged; event_log_index++)
    {
        event_log.event_log_index = event_log_index;
        status = fbe_api_get_event_log(&event_log, FBE_PACKAGE_ID_SEP_0);
        MUT_ASSERT_TRUE_MSG(status == FBE_STATUS_OK, "== Error : failed to get event log info ==");

        switch (event_log.event_log_info.msg_id)
        {
        case SEP_ERROR_CODE_RAID_HOST_SECTOR_INVALIDATED:
        case SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_DATA_SECTOR:
        case SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_PARITY_SECTOR:
        case SEP_ERROR_CODE_RAID_HOST_DATA_CHECKSUM_ERROR:
        case SEP_ERROR_CODE_RAID_HOST_PARITY_CHECKSUM_ERROR:
        case SEP_ERROR_CODE_RAID_HOST_COHERENCY_ERROR:
        case SEP_ERROR_CODE_RAID_HOST_PARITY_INVALIDATED:
        case SEP_ERROR_CODE_RAID_HOST_UNCORRECTABLE_SECTOR:
        case SEP_ERROR_CODE_RAID_HOST_LBA_STAMP_ERROR:
            message_count += 1;
            break;

        default:
            break;
        } /* end switch(event_log.event_log_info.msg_id) */
    } /* end for(event_log_index = 0; ...) ... */

    return message_count;
}
/*************************************************************
 * end edgar_the_bug_get_msg_count_relevant_to_error()
 *************************************************************/

/*!**************************************************************
 * edgar_the_bug_duplicate_config_array()
 ****************************************************************
 * @brief
 *  Make a copy of a config array to recreate 
 *
 * @param src_rg_config_array_p - raid group config array to recreate    
 *        dest_rg_config_array_p - duplicate raid group config array 
 *
 * @return
 *
 * @author
 *  6/7/2012 - Created. Dave Agans
 *
 ****************************************************************/
void edgar_the_bug_duplicate_config_array(fbe_test_rg_configuration_array_t *src_rg_config_array_p,
                                          fbe_test_rg_configuration_array_t *dest_rg_config_array_p)
{
    fbe_u32_t type_index = 0;
    fbe_u32_t group_index = 0;
    fbe_u32_t group_count = 0;
    fbe_test_rg_configuration_t * current_group_p = NULL;

    /* Types to copy must add one to copy the terminator */
    for (type_index = 0; type_index < EDGAR_THE_BUG_RAID_TYPE_COUNT + 1; type_index++)
    {
        current_group_p = &src_rg_config_array_p[type_index][0];

        /* Count groups to copy and add one to copy the terminator */
        group_count = fbe_test_get_rg_array_length(current_group_p) + 1;

        for (group_index = 0; group_index < group_count; group_index++)
        {
            dest_rg_config_array_p[type_index][group_index] = src_rg_config_array_p[type_index][group_index];
            dest_rg_config_array_p[type_index][group_index].b_create_this_pass = FBE_TRUE;
            
        }  /* for all groups */
    } /* for all types */
}
/******************************************
 * end edgar_the_bug_duplicate_config_array()
 ******************************************/

/*!**************************************************************
 * edgar_the_bug_shutdown_sp()
 ****************************************************************
 * @brief
 *  Do a hard reboot on the selected sp
 *
 * @param  
 *
 * @return 
 *
 * @author
 *  6/8/2012 - Created. Dave Agans
 *
 ****************************************************************/
void edgar_the_bug_shutdown_sp(fbe_sim_transport_connection_target_t sp)
{
    fbe_status_t status = FBE_STATUS_OK;

    status = fbe_api_sim_transport_set_target_server(sp);
    MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);

    mut_printf(MUT_LOG_LOW, " == SHUTDOWN %s == ", sp == FBE_SIM_SP_A ? "SP A"
                                                                      : "SP B");
    fbe_api_sim_transport_destroy_client(sp);
    fbe_test_sp_sim_stop_single_sp(sp == FBE_SIM_SP_A ? FBE_TEST_SPA
                                                      : FBE_TEST_SPB);

    /* we can't destroy fbe_api, because it's shared between two SPs */
    fbe_test_base_suite_startup_single_sp(sp);
}
/******************************************
 * end edgar_the_bug_shutdown_sp()
 ******************************************/

/*!**************************************************************
 * edgar_the_bug_startup_sp()
 ****************************************************************
 * @brief
 *  Startup the peer sp after a hard reboot and recreate the config
 *
 * @param none      
 *
 * @return 
 *
 * @author
 *  6/1/2012 - Created. Dave Agans
 *
 ****************************************************************/
void edgar_the_bug_startup_sp(fbe_sim_transport_connection_target_t sp,
                              fbe_test_rg_configuration_t *rg_config_p,
                              fbe_u32_t num_to_remove)
{
    fbe_status_t status = FBE_STATUS_OK;
    fbe_u32_t test_level = fbe_sep_test_util_get_raid_testing_extended_level();
    fbe_test_rg_configuration_t *current_rg_config_p;
    fbe_u32_t i = 0;
    fbe_u32_t raid_group_count = fbe_test_get_rg_array_length(rg_config_p);
    fbe_u32_t index = 0;

    status = fbe_api_sim_transport_set_target_server(sp);
    MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);

    mut_printf(MUT_LOG_LOW, " == STARTUP %s == ", sp == FBE_SIM_SP_A ? "SP A"
                                                                     : "SP B");

    /* Start the SP with a new session
     * NOTE: Must copy the rg_config array, because sep_config_load_sep_and_neit below will scramble the one used
     *        to load the physical config, and we need the rg_config array for the other SP and next run
     */
    /* rtl 1 and rtl 0 are the same for now */
    if (test_level == 0)
    {
        /* Qual.
         */
        edgar_the_bug_duplicate_config_array(&edgar_the_bug_raid_group_config_qual[0], &edgar_the_bug_temp_array[0]);
    }
    else
    {
        /* Extended. 
         */
        edgar_the_bug_duplicate_config_array(&edgar_the_bug_raid_group_config_qual[0], &edgar_the_bug_temp_array[0]);
    }

    fbe_test_sep_util_rg_config_array_load_physical_config(&edgar_the_bug_temp_array[0]);

    /* Re-remove the failed drives
     */
    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            for (i = 0; i < num_to_remove; i++)
            {
                mut_printf(MUT_LOG_TEST_STATUS, "Re-remove a drive for rgid: %d\n", current_rg_config_p->raid_group_id);

                status = fbe_test_pp_util_pull_drive(rg_config_p[index].rg_disk_set[current_rg_config_p->specific_drives_to_remove[i]].bus,
                                                     rg_config_p[index].rg_disk_set[current_rg_config_p->specific_drives_to_remove[i]].enclosure,
                                                     rg_config_p[index].rg_disk_set[current_rg_config_p->specific_drives_to_remove[i]].slot, 
                                                     &current_rg_config_p->drive_handle[i]);
                MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);

                mut_printf(MUT_LOG_TEST_STATUS, "Drive removed: %d_%d_%d\n", 
                           rg_config_p[index].rg_disk_set[current_rg_config_p->specific_drives_to_remove[i]].bus,
                           rg_config_p[index].rg_disk_set[current_rg_config_p->specific_drives_to_remove[i]].enclosure,
                           rg_config_p[index].rg_disk_set[current_rg_config_p->specific_drives_to_remove[i]].slot);
            }
        }
        current_rg_config_p++;
    }

    sep_config_load_sep_and_neit();
}
/******************************************
 * end edgar_the_bug_startup_sp()
 ******************************************/

/*!**************************************************************
 * edgar_the_bug_run_test_config()
 ****************************************************************
 * @brief
 *  Run edgar the bug on the rg config set
 *
 * @param rg_config_p - the raid group configuration to test
 *
 * @return None.   
 *
 * @author
 *  9/21/2011 - Created. Deanna Heng
 *  5/15/2012 - Modified for edgar_the_bug_test. Dave Agans
 *
 ****************************************************************/
void edgar_the_bug_run_test_config(fbe_test_rg_configuration_t *rg_config_p, void *test_case_in)
{
    edgar_the_bug_test_case_t *test_case = (edgar_the_bug_test_case_t *)test_case_in;

    mut_printf(MUT_LOG_TEST_STATUS, "=====Running edgar_the_bug test on %s - %s =====\n",
               test_case->target_sp == EDGAR_THE_BUG_ACTIVE_SP ? "Active SP"
                                                               : "Passive SP",
               test_case->b_quick_restart ? (test_case->b_restart_to_active ? "restart peer sp and kill target sp before flush"
                                                                            : "restart peer sp before flush")
                                          : "restart peer sp at end");

    edgar_the_bug_run_tests_in_parallel(rg_config_p,
                                        test_case->target_sp,
                                        test_case->b_quick_restart,
                                        test_case->b_restart_to_active,
                                        test_case->b_test_invalidated_write);

    return;
}
/******************************************
 * end edgar_the_bug_run_test_config()
 ******************************************/

/*!**************************************************************
 * edgar_the_bug_run_tests_in_parallel()
 ****************************************************************
 * @brief
 *  Run write log failover flush test on rg config
 *
 * @param rg_config_p - the raid group configuration to test
 *
 * @return None.   
 *
 * @author
 *  11/21/2011 - Created. Deanna Heng
 *  5/15/2012 - Modified for edgar_the_bug_test. Dave Agans
 *
 ****************************************************************/
void edgar_the_bug_run_tests_in_parallel(fbe_test_rg_configuration_t *rg_config_p,
                                         fbe_sim_transport_connection_target_t target_sp,
                                         fbe_bool_t b_quick_restart,
                                         fbe_bool_t b_restart_to_active,
                                         fbe_bool_t b_test_invalidated_write)
{
    fbe_status_t status = FBE_STATUS_OK;
    fbe_u32_t raid_group_count = fbe_test_get_rg_array_length(rg_config_p);
    fbe_u32_t enabled_raid_group_count = 0;
    fbe_u32_t index = 0;
    fbe_api_logical_error_injection_get_stats_t stats;
    fbe_u32_t i = 0;
    fbe_sim_transport_connection_target_t peer_sp;
    fbe_u32_t num_to_remove;
    fbe_u32_t block_count[EDGAR_THE_BUG_RAID_CONFIG_PER_TYPE_COUNT];
    fbe_lba_t lba[EDGAR_THE_BUG_RAID_CONFIG_PER_TYPE_COUNT];
    fbe_test_rg_configuration_t *current_rg_config_p;
    fbe_u32_t edgar_the_bug_current_number_physical_objects;
    fbe_u32_t message_count = 0;
    fbe_bool_t b_flushed;
    fbe_test_event_log_test_result_t log_expected_result[EDGAR_THE_BUG_RAID_CONFIG_PER_TYPE_COUNT];
    fbe_test_event_log_test_result_t log_unexpected_result[EDGAR_THE_BUG_RAID_CONFIG_PER_TYPE_COUNT];


    /* Lookup RG IDs and save them locally */
    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            status = fbe_api_database_lookup_raid_group_by_number(current_rg_config_p->raid_group_id, &rg_object_id[index]);
            MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);
            enabled_raid_group_count++;
        }
        current_rg_config_p++;
    }

    /* set the peer SP and select the target server */
    peer_sp = (target_sp == FBE_SIM_SP_A ? FBE_SIM_SP_B
                                         : FBE_SIM_SP_A);
    fbe_api_sim_transport_set_target_server(target_sp);

    /* bookkeeping to keep track of how many objects to wait for later
     */
    status = fbe_api_get_total_objects(&edgar_the_bug_current_number_physical_objects, FBE_PACKAGE_ID_PHYSICAL);
    MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);

    /* STEP 3: Disable background processes and write background pattern to rg
     */
    /*  Disable the recovery queue so that a spare cannot swap-in */
    fbe_test_sep_util_disable_recovery_queue(FBE_OBJECT_ID_INVALID);

    fbe_test_sep_drive_disable_background_zeroing_for_all_pvds();
    fbe_test_sep_drive_disable_sniff_verify_for_all_pvds();

    big_bird_write_background_pattern();

    /* Clear the event log so leftover messages from previous run don't trip us up. */
    mut_printf(MUT_LOG_TEST_STATUS, "== %s Clearing event log and stats for next run. ==", __FUNCTION__);
    status = fbe_api_clear_event_log(FBE_PACKAGE_ID_SEP_0);
    MUT_ASSERT_TRUE_MSG(status == FBE_STATUS_OK, "== %s Failed to clear SEP event log! == ");
    status = fbe_api_clear_event_log_statistics(FBE_PACKAGE_ID_SEP_0);
    MUT_ASSERT_TRUE_MSG(status == FBE_STATUS_OK, "== %s Failed to clear SEP event log statistics! == ");

    /* STEP 4: Insert write log flush start debug hook into raid group condition handler
     */
    mut_printf(MUT_LOG_TEST_STATUS, "== %s setting flush start hook \n", __FUNCTION__);
    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            status = fbe_api_scheduler_add_debug_hook(rg_object_id[index],
                                                      SCHEDULER_MONITOR_STATE_RAID_GROUP_JOURNAL_FLUSH,
                                                      FBE_RAID_GROUP_SUBSTATE_JOURNAL_FLUSH_START,
                                                      0, 0, SCHEDULER_CHECK_STATES, SCHEDULER_DEBUG_ACTION_PAUSE);
            MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);
        }
        current_rg_config_p++;
    }

    /* STEP 5: Remove drive(s) to create degraded array and delay IO on one of the drives on the passive side
     */

    fbe_api_sim_transport_set_target_server(peer_sp);

    /* first clear out any old error records, then create one new one for all raid groups */
    status = fbe_api_logical_error_injection_disable_records(0, FBE_LOGICAL_ERROR_INJECTION_MAX_RECORDS);
    MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);

    status = fbe_api_logical_error_injection_create_record(&edgar_the_bug_record_down);
    MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);

    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            edgar_the_bug_set_test_params(current_rg_config_p,
                                          &block_count[index],
                                          &lba[index],
                                          &num_to_remove,
                                          &log_expected_result[index],
                                          &log_unexpected_result[index]);

            for (i = 0; i < num_to_remove; i++)
            {
                mut_printf(MUT_LOG_TEST_STATUS, "Remove a drive for rgid: %d\n", current_rg_config_p->raid_group_id);
                edgar_the_bug_current_number_physical_objects -= 1;
                /*  Remove drive(s) in the RG.  Check the object states change correctly and that rb logging
                    is marked. */
                sep_rebuild_utils_remove_drive_and_verify(current_rg_config_p, 
                                                          current_rg_config_p->specific_drives_to_remove[i], 
                                                          edgar_the_bug_current_number_physical_objects,
                                                          &current_rg_config_p->drive_handle[i]);
                mut_printf(MUT_LOG_TEST_STATUS, "Verify drive removed (rebuild logging) for write log flush test");
                sep_rebuild_utils_verify_rb_logging(current_rg_config_p, current_rg_config_p->specific_drives_to_remove[i]);
                sep_rebuild_utils_check_for_reb_restart(current_rg_config_p, current_rg_config_p->specific_drives_to_remove[i]);
            }
            status = fbe_api_logical_error_injection_enable_object(rg_object_id[index], FBE_PACKAGE_ID_SEP_0);
            MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);
        }
        current_rg_config_p++;
    }

    if (b_test_invalidated_write != FBE_TRUE)
    {
        /* overall error injection enable */
        status = fbe_api_logical_error_injection_enable();
        MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);

        /* We should have 1 record and an enabled object.
         */
        status = fbe_api_logical_error_injection_get_stats(&stats);
        MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);
        MUT_ASSERT_INT_EQUAL(stats.b_enabled, FBE_TRUE);
        MUT_ASSERT_INT_EQUAL(stats.num_records, 1);
    }

    /* STEP 6: Run IOs to exercise write log and stripe lock
     */
    mut_printf(MUT_LOG_TEST_STATUS, "== %s starting I/O \n", __FUNCTION__);

    /* Launch the peer io for each raid group
     */
    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        mut_printf(MUT_LOG_TEST_STATUS, "== %s start peer SP IO rg:0x%x lba:0x%x blks:0x%x \n",
                   __FUNCTION__,
                   rg_object_id[index],
                   (unsigned int)lba[index],
                   block_count[index]);

        if (b_test_invalidated_write != FBE_TRUE)
        {
            status = fbe_api_rdgen_send_one_io_asynch(&edgar_the_bug_test_contexts[index][0],
                                                      rg_object_id[index],
                                                      FBE_CLASS_ID_PARITY,
                                                      FBE_PACKAGE_ID_SEP_0,
                                                      FBE_RDGEN_OPERATION_WRITE_ONLY,
                                                      FBE_RDGEN_PATTERN_LBA_PASS,
                                                      lba[index],
                                                      block_count[index],
                                                      FBE_RDGEN_OPTIONS_INVALID);
        }
        else
        {
            status = fbe_api_rdgen_send_one_io_asynch(&edgar_the_bug_test_contexts[index][0],
                                                      rg_object_id[index],
                                                      FBE_CLASS_ID_PARITY,
                                                      FBE_PACKAGE_ID_SEP_0,
                                                      FBE_RDGEN_OPERATION_CORRUPT_CRC_READ_CHECK,
                                                      FBE_RDGEN_PATTERN_LBA_PASS,
                                                      lba[index],
                                                      block_count[index],
                                                      FBE_RDGEN_OPTIONS_DO_NOT_RANDOMIZE_CORRUPT_OPERATION);
        }

        MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);
    }

    /* Allow incomplete I/O to fester for 6 seconds.
     * Note that with only 2 seconds here, the target SP could occasionally get the stripe lock first,
     *   and thus its io would not be locked out by the incomplete io.
     */
    fbe_api_sleep(6000);

    /* restore the target sp */
    fbe_api_sim_transport_set_target_server(target_sp);

    if (b_test_invalidated_write != FBE_TRUE)
    {
        /* Launch the local io for each raid group
         */
        current_rg_config_p = rg_config_p;
        for (index = 0; index < raid_group_count; index++)
        {
            mut_printf(MUT_LOG_TEST_STATUS, "== %s start target SP IO rg:0x%x lba:0x%llx blks:0x%x \n",
                       __FUNCTION__,
                       rg_object_id[index],
                       lba[index],
                       block_count[index]+2);

            status = fbe_api_rdgen_send_one_io_asynch(&edgar_the_bug_test_contexts[index][1],
                                                      rg_object_id[index],
                                                      FBE_CLASS_ID_PARITY,
                                                      FBE_PACKAGE_ID_SEP_0,
                                                      FBE_RDGEN_OPERATION_WRITE_ONLY,
                                                      FBE_RDGEN_PATTERN_LBA_PASS,
                                                      lba[index],
                                                      block_count[index] + 2,  /* to distinguish it in logs */
                                                      FBE_RDGEN_OPTIONS_INVALID);

            MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);
        }

        /* Allow locked-out I/O to fester for 2 seconds.
         */
        fbe_api_sleep(2000);
    }

    /* STEP 7: Shutdown active SP, passive SP, or both SPs
     *         Peer SP is the one to shut down, routine is called with active or passive SP as param
     */

    /* Reboot the peer SP */
    edgar_the_bug_shutdown_sp(peer_sp);

    status = fbe_api_sim_transport_set_target_server(target_sp);
    MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);

    /* set dual sp mode to single while the peer is down */
    fbe_test_sep_util_set_dualsp_test_mode(FBE_FALSE);

    /* STEP 8: Restart SP (if testing simultaneous restart and flush)
     */
    if (b_quick_restart)
    {
        /* bring dual sp mode back to dual before bringing peer up
         */
        fbe_test_sep_util_set_dualsp_test_mode(FBE_TRUE);

        edgar_the_bug_startup_sp(peer_sp, rg_config_p, num_to_remove);

        /* Set back to target sp to wait for first flush
         */
        status = fbe_api_sim_transport_set_target_server(target_sp);
        MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);
    }


    /* STEP 9: Wait for write log flush start
     */
    mut_printf(MUT_LOG_TEST_STATUS, "== %s waiting for flush start hook \n", __FUNCTION__);

    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            status = fbe_test_wait_for_debug_hook(rg_object_id[index], 
                                                 SCHEDULER_MONITOR_STATE_RAID_GROUP_JOURNAL_FLUSH,
                                                 FBE_RAID_GROUP_SUBSTATE_JOURNAL_FLUSH_START,
                                                 SCHEDULER_CHECK_STATES, SCHEDULER_DEBUG_ACTION_PAUSE, 0,0);
            MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);
        }
        current_rg_config_p++;
    }

    /* STEP 10: Set flush done hook, clear flush start hook to allow flush to continue
     */
    /* Allow incomplete I/O to fester for 5 seconds.
     */
    mut_printf(MUT_LOG_TEST_STATUS, "== %s pausing to make sure locked-out io waits for flush\n", __FUNCTION__);
    fbe_api_sleep(5000);

    /* If restart to active, move flush hook over to peer and kill target
     */
    if (b_quick_restart && b_restart_to_active)
    {
        fbe_api_sim_transport_set_target_server(peer_sp);

        mut_printf(MUT_LOG_TEST_STATUS, "== %s setting peer flush start hook \n", __FUNCTION__);

        current_rg_config_p = rg_config_p;
        for (index = 0; index < raid_group_count; index++)
        {
            if (fbe_test_rg_config_is_enabled(current_rg_config_p))
            {
                status = fbe_api_scheduler_add_debug_hook(rg_object_id[index],
                                                          SCHEDULER_MONITOR_STATE_RAID_GROUP_JOURNAL_FLUSH,
                                                          FBE_RAID_GROUP_SUBSTATE_JOURNAL_FLUSH_START,
                                                          0, 0, SCHEDULER_CHECK_STATES, SCHEDULER_DEBUG_ACTION_PAUSE);
                MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);
            }
            current_rg_config_p++;
        }

        edgar_the_bug_shutdown_sp(target_sp);
        fbe_api_sim_transport_set_target_server(peer_sp);

        /* Go back to single sp mode since target is down
         */
        fbe_test_sep_util_set_dualsp_test_mode(FBE_FALSE);

        mut_printf(MUT_LOG_TEST_STATUS, "== %s waiting for restarted sp flush start hook \n", __FUNCTION__);

        current_rg_config_p = rg_config_p;
        for (index = 0; index < raid_group_count; index++)
        {
            if (fbe_test_rg_config_is_enabled(current_rg_config_p))
            {
                status = fbe_test_wait_for_debug_hook(rg_object_id[index], 
                                                     SCHEDULER_MONITOR_STATE_RAID_GROUP_JOURNAL_FLUSH,
                                                     FBE_RAID_GROUP_SUBSTATE_JOURNAL_FLUSH_START,
                                                     SCHEDULER_CHECK_STATES, SCHEDULER_DEBUG_ACTION_PAUSE, 0,0);
                MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);
            }
            current_rg_config_p++;
        }
    }

    mut_printf(MUT_LOG_TEST_STATUS, "== %s setting flush done and deleting flush start hook \n", __FUNCTION__);

    /* remove hooks on selected SP */
    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            status = fbe_api_scheduler_add_debug_hook(rg_object_id[index],
                                                      SCHEDULER_MONITOR_STATE_RAID_GROUP_JOURNAL_FLUSH,
                                                      FBE_RAID_GROUP_SUBSTATE_JOURNAL_FLUSH_DONE,
                                                      0, 0, SCHEDULER_CHECK_STATES, SCHEDULER_DEBUG_ACTION_PAUSE);
            MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);

            status = fbe_api_scheduler_del_debug_hook(rg_object_id[index],
                                                      SCHEDULER_MONITOR_STATE_RAID_GROUP_JOURNAL_FLUSH,
                                                      FBE_RAID_GROUP_SUBSTATE_JOURNAL_FLUSH_START,
                                                      0, 0, SCHEDULER_CHECK_STATES, SCHEDULER_DEBUG_ACTION_PAUSE);
            MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);
        }
        current_rg_config_p++;
    }

    /* STEP 11: Wait for flush done and remove hook
     */
    mut_printf(MUT_LOG_TEST_STATUS, "== %s wait for flush done and check for leftover on-disk valid headers\n", __FUNCTION__);

    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            status = fbe_test_wait_for_debug_hook(rg_object_id[index], 
                                                 SCHEDULER_MONITOR_STATE_RAID_GROUP_JOURNAL_FLUSH,
                                                 FBE_RAID_GROUP_SUBSTATE_JOURNAL_FLUSH_DONE,
                                                 SCHEDULER_CHECK_STATES, SCHEDULER_DEBUG_ACTION_PAUSE, 0,0);
            MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);

            /* Check that the flush did not leave any valid slot headers on disk
             */
            status = edgar_the_bug_verify_write_log_flushed(rg_object_id[index], FBE_FALSE, FBE_PARITY_WRITE_LOG_INVALID_SLOT, &b_flushed); /* Verify all slots */
            MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);
            MUT_ASSERT_INT_EQUAL(FBE_TRUE, b_flushed);

            status = fbe_api_scheduler_del_debug_hook(rg_object_id[index],
                                                      SCHEDULER_MONITOR_STATE_RAID_GROUP_JOURNAL_FLUSH,
                                                      FBE_RAID_GROUP_SUBSTATE_JOURNAL_FLUSH_DONE,
                                                      0, 0, SCHEDULER_CHECK_STATES, SCHEDULER_DEBUG_ACTION_PAUSE);
            MUT_ASSERT_INT_EQUAL(FBE_STATUS_OK, status);
        }
        current_rg_config_p++;
    }

    /* STEP 12: Check for verify errors on locked out write
     */
    /* Allow locked-out I/O to finish.
     */
    fbe_api_sleep(5000);

    mut_printf(MUT_LOG_TEST_STATUS, "== %s Checking for unlocked write verify errors. ==", __FUNCTION__);
    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            if (b_test_invalidated_write != FBE_TRUE)
            {
                message_count = edgar_the_bug_get_msg_count_relevant_to_error();
                MUT_ASSERT_INT_EQUAL(0, message_count);
            }
        }
        current_rg_config_p++;
    }
    mut_printf(MUT_LOG_TEST_STATUS, "== %s Check for unlocked write verify errors finished. ==", __FUNCTION__);


    /* STEP 13: Re-insert drive(s)
     */
    /* Restore dual SP if both are up
     */
    if (b_quick_restart && !b_restart_to_active)
    {
        fbe_test_sep_util_set_dualsp_test_mode(FBE_TRUE);
    }

    /* Re-insert drive(s) in one loop, wait for rebuild in a second loop, to let rebuilds run in parallel
     */
    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            for (i = 0; i < num_to_remove; i++)
            {
                edgar_the_bug_current_number_physical_objects += 1;
                sep_rebuild_utils_reinsert_drive_and_verify(current_rg_config_p, 
                                                            current_rg_config_p->specific_drives_to_remove[i], 
                                                            edgar_the_bug_current_number_physical_objects, 
                                                            &current_rg_config_p->drive_handle[i]);
            }
        }
        current_rg_config_p++;
    }
    /* Wait for rebuild in a second loop to let rebuilds run in parallel
     */
    mut_printf(MUT_LOG_TEST_STATUS, "== %s Waiting for drive rebuilds to finish. ==", __FUNCTION__);
    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            for (i = 0; i < num_to_remove; i++)
            {
                sep_rebuild_utils_wait_for_rb_comp(current_rg_config_p, current_rg_config_p->specific_drives_to_remove[i]);
            }
        }
        current_rg_config_p++;
    }

    /* STEP 14: Check for rebuild errors and leftover on-disk valid headers, now that all disks are restored
     */

    mut_printf(MUT_LOG_TEST_STATUS, "== %s Checking for rebuild errors and leftover on-disk valid headers. ==", __FUNCTION__);
    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            if (b_test_invalidated_write != FBE_TRUE)
            {
                message_count = edgar_the_bug_get_msg_count_relevant_to_error();
                MUT_ASSERT_INT_EQUAL(0, message_count);
            }
            else
            {
#if 0 /*!@todo DJA -- find out why Arun removed this, fix the problem, and restore it */
                mumford_the_magician_validates_event_log_message(&log_expected_result[index],
                                                                 rg_object_id[index],
                                                                 FBE_TRUE); /* TRUE = verify message present */
                mumford_the_magician_validates_event_log_message(&log_unexpected_result[index],
                                                                 rg_object_id[index],
                                                                 FBE_FALSE); /* FALSE = verify message not present */
#endif
            }
        }
        current_rg_config_p++;
    }
    mut_printf(MUT_LOG_TEST_STATUS, "== %s Check for rebuild errors finished. ==", __FUNCTION__);

    /* STEP 15: Restart background processes and SP (if not testing simultaneous restart and flush)
     */
    if (!b_quick_restart)
    {
        /* We never brought up the peer SP, do it now
         */
        fbe_test_sep_util_set_dualsp_test_mode(FBE_TRUE);
        edgar_the_bug_startup_sp(peer_sp, rg_config_p, 0);
    }
    else if (b_restart_to_active)
    {
        /* We killed the target sp, bring it up now
         */
        fbe_test_sep_util_set_dualsp_test_mode(FBE_TRUE);
        edgar_the_bug_startup_sp(target_sp, rg_config_p, 0);
    }

    /* destroy test contexts for the next run */
    current_rg_config_p = rg_config_p;
    for (index = 0; index < raid_group_count; index++)
    {
        if (fbe_test_rg_config_is_enabled(current_rg_config_p))
        {
            status = fbe_api_rdgen_test_context_destroy(&edgar_the_bug_test_contexts[index][0]);
            MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);
            if (b_test_invalidated_write != FBE_TRUE)
            {
                status = fbe_api_rdgen_test_context_destroy(&edgar_the_bug_test_contexts[index][1]);
                MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);
            }
        }
        current_rg_config_p++;
    }

    /* overall error injection enable */
    status = fbe_api_logical_error_injection_disable();
    MUT_ASSERT_INT_EQUAL(status, FBE_STATUS_OK);

    /*  Enable the recovery queue at the end of the test */
    fbe_test_sep_util_enable_recovery_queue(FBE_OBJECT_ID_INVALID);

}
/******************************************
 * end edgar_the_bug_run_tests_in_parallel()
 ******************************************/

/*!**************************************************************
 * edgar_the_bug_get_test_case_array_length()
 ****************************************************************
 * @brief
 *  Get the number of test cases in the array.
 *  Loops until it hits the terminator.
 *
 * @param test_case_array_p - array of test cases.               
 *
 * @return fbe_u32_t number of test cases.  
 *
 ****************************************************************/
fbe_u32_t edgar_the_bug_get_test_case_array_length(edgar_the_bug_test_case_t *test_case_array_p)
{
    fbe_u32_t num_test_cases = 0;

    /* Loop until we find the table number or we hit the terminator.
     */
    while (test_case_array_p->target_sp != FBE_SIM_INVALID_SERVER)
    {
        num_test_cases++;
        test_case_array_p++;
    }
    return num_test_cases;
}
/**************************************
 * end edgar_the_bug_get_test_case_array_length()
 **************************************/

/*!**************************************************************
 * edgar_the_bug_test()
 ****************************************************************
 * @brief
 *  Run edgar_the_bug test
 *
 * @param None.               
 *
 * @return None.   
 *
 * @author
 *  9/21/2011 - Created. Deanna Heng
 *  5/15/2012 - Modified for edgar_the_bug_test. Dave Agans
 *
 ****************************************************************/
void edgar_the_bug_dualsp_test(void)
{
    fbe_u32_t                   raid_type_index = 0;
    fbe_u32_t                   test_case_index = 0;
    const fbe_char_t            *raid_type_string_p = NULL;
    fbe_test_rg_configuration_t *rg_config_p = NULL;
    fbe_u32_t                   testing_level = fbe_sep_test_util_get_raid_testing_extended_level();
    fbe_u32_t                   raid_group_count = 0;
    fbe_u32_t                   test_case_count = 0;

    /* Enable dualsp mode
     */
    fbe_test_sep_util_set_dualsp_test_mode(FBE_TRUE);

    /* rtl 1 and rtl 0 are the same for now */
    for (raid_type_index = 0; raid_type_index < EDGAR_THE_BUG_RAID_TYPE_COUNT; raid_type_index++)
    {
        if (testing_level == 0)
        {
            /* Qual.
             */
            rg_config_p = &edgar_the_bug_raid_group_config_qual[raid_type_index][0];
            test_case_count = 1;
        }
        else
        {
            /* Extended. 
             */
            rg_config_p = &edgar_the_bug_raid_group_config_qual[raid_type_index][0];
            test_case_count = edgar_the_bug_get_test_case_array_length(edgar_the_bug_test_case_array);
        }
        fbe_test_sep_util_get_raid_type_string(rg_config_p->raid_type, &raid_type_string_p);
        if (!fbe_sep_test_util_raid_type_enabled(rg_config_p->raid_type))
        {
            mut_printf(MUT_LOG_TEST_STATUS, "raid type %s (%d)not enabled", raid_type_string_p, rg_config_p->raid_type);
            continue;
        }
        raid_group_count = fbe_test_get_rg_array_length(rg_config_p);
        if (raid_group_count == 0)
        {
            continue;
        }

        for (test_case_index = 0; test_case_index < test_case_count; test_case_index++)
        {

           if ((test_case_index + 1 >= test_case_count) && (raid_type_index + 1 >= EDGAR_THE_BUG_RAID_TYPE_COUNT)) {
               /* Now create the raid groups and run the test 
                */
               fbe_test_run_test_on_rg_config(rg_config_p, 
                                              &edgar_the_bug_test_case_array[test_case_index],                                       /* no test case objects needed */
                                              edgar_the_bug_run_test_config,
                                              EDGAR_THE_BUG_LUNS_PER_RAID_GROUP,
                                              EDGAR_THE_BUG_CHUNKS_PER_LUN);
           }
           else {
              fbe_test_run_test_on_rg_config_with_time_save(rg_config_p, 
                                              &edgar_the_bug_test_case_array[test_case_index],                                       /* no test case objects needed */
                                              edgar_the_bug_run_test_config,
                                              EDGAR_THE_BUG_LUNS_PER_RAID_GROUP,
                                              EDGAR_THE_BUG_CHUNKS_PER_LUN,
                                              FBE_FALSE);
           }
        }

    }    /* for all raid types. */

    /* Always clear dualsp mode */
    fbe_test_sep_util_set_dualsp_test_mode(FBE_FALSE);

    return;
}

/******************************************
 * end edgar_the_bug_test()
 ******************************************/

/*!**************************************************************
 * edgar_the_bug_setup()
 ****************************************************************
 * @brief
 *  Setup for edgar_the_bug test.
 *
 * @param None.               
 *
 * @return None.   
 *
 * @author
 *  9/21/2011 - Created. Deanna Heng
 *  5/15/2012 - Modified for edgar_the_bug_test. Dave Agans
 *
 ****************************************************************/
void edgar_the_bug_dualsp_setup(void)
{
    fbe_u32_t                   raid_type_index = 0;
    const fbe_char_t            *raid_type_string_p = NULL;
    fbe_test_rg_configuration_t *rg_config_p = NULL;
    fbe_u32_t test_level = fbe_sep_test_util_get_raid_testing_extended_level();
    fbe_u32_t raid_group_count = 0;
    fbe_test_rg_configuration_array_t *array_p = NULL;

    mumford_the_magician_common_setup();

    if (fbe_test_util_is_simulation())
    {
        /* rtl 1 and rtl 0 are the same for now */
        if (test_level == 0)
        {
            /* Qual.
             */
            array_p = &edgar_the_bug_raid_group_config_qual[0];
        }
        else
        {
            /* Extended. 
             */
            array_p = &edgar_the_bug_raid_group_config_qual[0];
        }
        for (raid_type_index = 0; raid_type_index < EDGAR_THE_BUG_RAID_TYPE_COUNT; raid_type_index++)
        {
            rg_config_p = &array_p[raid_type_index][0];

            fbe_test_sep_util_get_raid_type_string(rg_config_p->raid_type, &raid_type_string_p);
            if (!fbe_sep_test_util_raid_type_enabled(rg_config_p->raid_type))
            {
                mut_printf(MUT_LOG_TEST_STATUS, "raid type %s (%d)not enabled",
                           raid_type_string_p,
                           rg_config_p->raid_type);
                continue;
            }
            raid_group_count = fbe_test_get_rg_array_length(rg_config_p);
            if (raid_group_count == 0)
            {
                continue;
            }

            /* Initialize the raid group configuration 
             */
            fbe_test_sep_util_init_rg_configuration_array(rg_config_p);
            fbe_test_rg_setup_random_block_sizes(rg_config_p);
            fbe_test_sep_util_randomize_rg_configuration_array(rg_config_p);

        } /* for all raid types. */

        fbe_api_sim_transport_set_target_server(EDGAR_THE_BUG_ACTIVE_SP);
        fbe_test_sep_util_rg_config_array_load_physical_config(array_p);

        fbe_api_sim_transport_set_target_server(EDGAR_THE_BUG_PASSIVE_SP);
        fbe_test_sep_util_rg_config_array_load_physical_config(array_p);

        sep_config_load_sep_and_neit_both_sps();

        /* Set the default target server back to A
         */
        fbe_api_sim_transport_set_target_server(EDGAR_THE_BUG_ACTIVE_SP);
    }

    /* Initialize any required fields 
     */
    fbe_test_common_util_test_setup_init();
    return;
}
/******************************************
 * end edgar_the_bug_dualsp_setup()
 ******************************************/

/*!**************************************************************
 * edgar_the_bug_cleanup()
 ****************************************************************
 * @brief
 *  Cleanup the edgar_the_bug test.
 *
 * @param None.               
 *
 * @return None.
 *
 * @author
 *  9/21/2011 - Created. Deanna Heng
 *  5/15/2012 - Modified for edgar_the_bug_test. Dave Agans
 *
 ****************************************************************/

void edgar_the_bug_dualsp_cleanup(void)
{
    mut_printf(MUT_LOG_HIGH, "%s entry", __FUNCTION__);
    if (fbe_test_util_is_simulation())
    {
        /* First execute teardown on SP B then on SP A
        */
        fbe_api_sim_transport_set_target_server(FBE_SIM_SP_B);
        fbe_test_sep_util_destroy_neit_sep_physical();

        /* First execute teardown on SP A
         */
        fbe_api_sim_transport_set_target_server(FBE_SIM_SP_A);
        fbe_test_sep_util_destroy_neit_sep_physical();
    }
    mumford_the_magician_common_cleanup();

    return;
}
/******************************************
 * end edgar_the_bug_dual_sp_cleanup()
 ******************************************/

/*************************
* end file edgar_the_bug_test.c
*************************/



